{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametrized Quantum Circuits for Reinforcement Learning\n",
    "\n",
    "\n",
    "Quantum computers have been shown to provide computational advantages in certain problem areas. The field of quantum reinforcement learning (QRL) aims to harness this boost by designing RL agents that rely on quantum models of computation.\n",
    "\n",
    "In this tutorial, you will implement two reinforcement learning algorithms based on parametrized/variational quantum circuits (PQCs or VQCs), namely a policy-gradient and a deep Q-learning implementation. These algorithms were introduced by [[1] Jerbi et al.](https://arxiv.org/abs/2103.05577) and [[2] Skolik et al.](https://arxiv.org/abs/2103.15084), respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement a PQC with data re-uploading in TFQ, and use it as:\n",
    "1. an RL policy trained with a policy-gradient method,\n",
    "2. a Q-function approximator trained with deep Q-learning,\n",
    "\n",
    "each solving [CartPole-v1](http://gym.openai.com/envs/CartPole-v1/), a benchmarking task from OpenAI Gym. Note that, as showcased in [[1]](https://arxiv.org/abs/2103.05577) and [[2]](https://arxiv.org/abs/2103.15084), these agents can also be used to solve other task-environment from OpenAI Gym, such as [FrozenLake-v0](http://gym.openai.com/envs/FrozenLake-v0/), [MountainCar-v0](http://gym.openai.com/envs/MountainCar-v0/) or [Acrobot-v1](http://gym.openai.com/envs/Acrobot-v1/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features of this implementation:\n",
    "- you will learn how to use a `tfq.layers.ControlledPQC` to implement a PQC with data re-uploading, appearing in many applications of QML. This implementation also naturally allows using trainable scaling parameters at the input of the PQC, to increase its expressivity,\n",
    "- you will learn how to implement observables with trainable weights at the output of a PQC, to allow a flexible range of output values,\n",
    "- you will learn how a `tf.keras.Model` can be trained with non-trivial ML loss functions, i.e., that are not compatible with `model.compile` and `model.fit`, using a `tf.GradientTape`.\n",
    "\n",
    "\n",
    "Now import TensorFlow and the module dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-23 23:11:55.542813: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-23 23:11:57.027034: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-23 23:11:57.074325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-23 23:11:57.074847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:2d:00.0 name: NVIDIA GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 68 deviceMemorySize: 9.76GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2021-09-23 23:11:57.074870: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-23 23:11:57.077419: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-09-23 23:11:57.077473: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-09-23 23:11:57.078402: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-23 23:11:57.078638: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-23 23:11:57.079306: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-09-23 23:11:57.079665: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-09-23 23:11:57.079743: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-09-23 23:11:57.079827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-23 23:11:57.080117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-23 23:11:57.080356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-09-23 23:11:57.081897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-23 23:11:57.082154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:2d:00.0 name: NVIDIA GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 68 deviceMemorySize: 9.76GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2021-09-23 23:11:57.082199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-23 23:11:57.082462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-23 23:11:57.082691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-09-23 23:11:57.082713: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-23 23:11:57.371934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-23 23:11:57.371954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-09-23 23:11:57.371959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-09-23 23:11:57.372146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-23 23:11:57.372438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-23 23:11:57.372702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-23 23:11:57.372946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5982 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:2d:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "\n",
    "import gym, cirq, sympy\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from collections import deque, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "from tqdm.notebook import trange, tqdm\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mlautaro-hickmann\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-23 23:11:59.105498: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.12.2<br/>\n                Syncing run <strong style=\"color:#cdcd00\">Run-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/lautaro-hickmann/CartPole-V1\" target=\"_blank\">https://wandb.ai/lautaro-hickmann/CartPole-V1</a><br/>\n                Run page: <a href=\"https://wandb.ai/lautaro-hickmann/CartPole-V1/runs/2mq3k9h3\" target=\"_blank\">https://wandb.ai/lautaro-hickmann/CartPole-V1/runs/2mq3k9h3</a><br/>\n                Run data is saved locally in <code>/home/lh/Documents/Q-RL_tests/wandb/run-20210923_231158-2mq3k9h3</code><br/><br/>\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"CartPole-V1\",\n",
    "           group=\"QML-Analytical\",         \n",
    "           name=\"Run-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build a PQC with data re-uploading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the core of both RL algorithms you are implementing is a PQC that takes as input the agent's state $s$ in the environment (i.e., a numpy array) and outputs a vector of expectation values. These expectation values are then post-processed, either to produce an agent's policy $\\pi(a|s)$ or approximate Q-values $Q(s,a)$. In this way, the PQCs are playing an analog role to that of deep neural networks in modern deep RL algorithms.\n",
    "\n",
    "A popular way to encode an input vector in a PQC is through the use of single-qubit rotations, where rotation angles are controlled by the components of this input vector. In order to get a [highly-expressive model](https://arxiv.org/abs/2008.08605), these single-qubit encodings are not performed only once in the PQC, but in several \"[re-uploadings](https://quantum-journal.org/papers/q-2020-02-06-226/)\", interlayed with variational gates. The layout of such a PQC is depicted below:\n",
    "\n",
    "<img src=\"images/pqc_re-uploading.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in [[1]](https://arxiv.org/abs/2103.05577) and [[2]](https://arxiv.org/abs/2103.15084), a way to further enhance the expressivity and trainability of data re-uploading PQCs is to use trainable input-scaling parameters $\\boldsymbol{\\lambda}$ for each encoding gate of the PQC, and trainable observable weights $\\boldsymbol{w}$ at its output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Cirq circuit for ControlledPQC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to implement in Cirq the quantum circuit to be used as the PQC. For this, start by defining basic unitaries to be applied in the circuits, namely an arbitrary single-qubit rotation and an entangling layer of CZ gates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def one_qubit_rotation(qubit, symbols):\n",
    "    \"\"\"\n",
    "    Returns Cirq gates that apply a rotation of the bloch sphere about the X,\n",
    "    Y and Z axis, specified by the values in `symbols`.\n",
    "    \"\"\"\n",
    "    return [cirq.rx(symbols[0])(qubit),\n",
    "            cirq.ry(symbols[1])(qubit),\n",
    "            cirq.rz(symbols[2])(qubit)]\n",
    "\n",
    "def entangling_layer(qubits):\n",
    "    \"\"\"\n",
    "    Returns a layer of CZ entangling gates on `qubits` (arranged in a circular topology).\n",
    "    \"\"\"\n",
    "    cz_ops = [cirq.CZ(q0, q1) for q0, q1 in zip(qubits, qubits[1:])]\n",
    "    cz_ops += ([cirq.CZ(qubits[0], qubits[-1])] if len(qubits) != 2 else [])\n",
    "    return cz_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use these functions to generate the Cirq circuit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_circuit(qubits, n_layers):\n",
    "    \"\"\"Prepares a data re-uploading circuit on `qubits` with `n_layers` layers.\"\"\"\n",
    "    # Number of qubits\n",
    "    n_qubits = len(qubits)\n",
    "    \n",
    "    # Sympy symbols for variational angles\n",
    "    params = sympy.symbols(f'theta(0:{3*(n_layers+1)*n_qubits})')\n",
    "    params = np.asarray(params).reshape((n_layers + 1, n_qubits, 3))\n",
    "    \n",
    "    # Sympy symbols for encoding angles\n",
    "    inputs = sympy.symbols(f'x(0:{n_qubits})'+f'(0:{n_layers})')\n",
    "    inputs = np.asarray(inputs).reshape((n_layers, n_qubits))\n",
    "    \n",
    "    # Define circuit\n",
    "    circuit = cirq.Circuit()\n",
    "    for l in range(n_layers):\n",
    "        # Variational layer\n",
    "        circuit += cirq.Circuit(one_qubit_rotation(q, params[l, i]) for i, q in enumerate(qubits))\n",
    "        circuit += entangling_layer(qubits)\n",
    "        # Encoding layer\n",
    "        circuit += cirq.Circuit(cirq.rx(inputs[l, i])(q) for i, q in enumerate(qubits))\n",
    "\n",
    "    # Last varitional layer\n",
    "    circuit += cirq.Circuit(one_qubit_rotation(q, params[n_layers, i]) for i,q in enumerate(qubits))\n",
    "    \n",
    "    return circuit, list(params.flat), list(inputs.flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that this produces a circuit that is alternating between variational and encoding layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<cirq.contrib.svg.svg.SVGCircuit at 0x7f64bce388e0>",
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"947.7660156250001\" height=\"150.0\"><line x1=\"32.246796875\" x2=\"917.7660156250001\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"917.7660156250001\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"917.7660156250001\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"375.7502734375\" x2=\"375.7502734375\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"435.7502734375\" x2=\"435.7502734375\" y1=\"75.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"495.7502734375\" x2=\"495.7502734375\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"55.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"10.0\" y=\"105.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 2): </text><rect x=\"74.49359375\" y=\"5.0\" width=\"73.7522265625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"111.36970703125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta0)</text><rect x=\"74.49359375\" y=\"55.0\" width=\"73.7522265625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"111.36970703125\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta3)</text><rect x=\"74.49359375\" y=\"105.0\" width=\"73.7522265625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"111.36970703125\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta6)</text><rect x=\"168.24582031249997\" y=\"5.0\" width=\"73.7522265625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"205.12193359375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta1)</text><rect x=\"168.24582031249997\" y=\"55.0\" width=\"73.7522265625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"205.12193359375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta4)</text><rect x=\"168.24582031249997\" y=\"105.0\" width=\"73.7522265625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"205.12193359375\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta7)</text><rect x=\"261.998046875\" y=\"5.0\" width=\"73.7522265625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"298.87416015625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta2)</text><rect x=\"261.998046875\" y=\"55.0\" width=\"73.7522265625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"298.87416015625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta5)</text><rect x=\"261.998046875\" y=\"105.0\" width=\"73.7522265625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"298.87416015625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta8)</text><circle cx=\"375.7502734375\" cy=\"25.0\" r=\"10.0\" /><circle cx=\"375.7502734375\" cy=\"75.0\" r=\"10.0\" /><circle cx=\"435.7502734375\" cy=\"75.0\" r=\"10.0\" /><circle cx=\"435.7502734375\" cy=\"125.0\" r=\"10.0\" /><circle cx=\"495.7502734375\" cy=\"25.0\" r=\"10.0\" /><circle cx=\"495.7502734375\" cy=\"125.0\" r=\"10.0\" /><rect x=\"535.7502734375\" y=\"5.0\" width=\"57.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"564.45060546875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(x00)</text><rect x=\"535.7502734375\" y=\"55.0\" width=\"57.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"564.45060546875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(x10)</text><rect x=\"535.7502734375\" y=\"105.0\" width=\"57.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"564.45060546875\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(x20)</text><rect x=\"613.1509375\" y=\"5.0\" width=\"81.538359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"653.9201171875001\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta9)</text><rect x=\"613.1509375\" y=\"55.0\" width=\"81.538359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"653.9201171875001\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta12)</text><rect x=\"613.1509375\" y=\"105.0\" width=\"81.538359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"653.9201171875001\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta15)</text><rect x=\"714.6892968750001\" y=\"5.0\" width=\"81.538359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"755.4584765625001\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta10)</text><rect x=\"714.6892968750001\" y=\"55.0\" width=\"81.538359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"755.4584765625001\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta13)</text><rect x=\"714.6892968750001\" y=\"105.0\" width=\"81.538359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"755.4584765625001\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta16)</text><rect x=\"816.2276562500001\" y=\"5.0\" width=\"81.538359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"856.9968359375001\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta11)</text><rect x=\"816.2276562500001\" y=\"55.0\" width=\"81.538359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"856.9968359375001\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta14)</text><rect x=\"816.2276562500001\" y=\"105.0\" width=\"81.538359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"856.9968359375001\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta17)</text></svg>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubits, n_layers = 3, 1\n",
    "qubits = cirq.GridQubit.rect(1, n_qubits)\n",
    "circuit, _, _ = generate_circuit(qubits, n_layers)\n",
    "SVGCircuit(circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReUploadingPQC layer using ControlledPQC\n",
    "\n",
    "To construct the re-uploading PQC from the figure above, you can create a custom Keras layer. This layer will manage the trainable parameters (variational angles $\\boldsymbol{\\theta}$ and input-scaling parameters $\\boldsymbol{\\lambda}$) and resolve the input values (input state $s$) into the appropriate symbols in the circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ReUploadingPQC(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Performs the transformation (s_1, ..., s_d) -> (theta_1, ..., theta_N, lmbd[1][1]s_1, ..., lmbd[1][M]s_1,\n",
    "        ......., lmbd[d][1]s_d, ..., lmbd[d][M]s_d) for d=input_dim, N=theta_dim and M=n_layers.\n",
    "    An activation function from tf.keras.activations, specified by `activation` ('linear' by default) is\n",
    "        then applied to all lmbd[i][j]s_i.\n",
    "    All angles are finally permuted to follow the alphabetical order of their symbol names, as processed\n",
    "        by the ControlledPQC.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, qubits, n_layers, observables, activation=\"linear\", name=\"re-uploading_PQC\"):\n",
    "        super(ReUploadingPQC, self).__init__(name=name)\n",
    "        self.n_layers = n_layers\n",
    "        self.n_qubits = len(qubits)\n",
    "\n",
    "        circuit, theta_symbols, input_symbols = generate_circuit(qubits, n_layers)\n",
    "\n",
    "        theta_init = tf.random_uniform_initializer(minval=0.0, maxval=np.pi)\n",
    "        self.theta = tf.Variable(\n",
    "            initial_value=theta_init(shape=(1, len(theta_symbols)), dtype=\"float32\"),\n",
    "            trainable=True, name=\"thetas\"\n",
    "        )\n",
    "        \n",
    "        lmbd_init = tf.ones(shape=(self.n_qubits * self.n_layers,))\n",
    "        self.lmbd = tf.Variable(\n",
    "            initial_value=lmbd_init, dtype=\"float32\", trainable=True, name=\"lambdas\"\n",
    "        )\n",
    "        \n",
    "        # Define explicit symbol order.\n",
    "        symbols = [str(symb) for symb in theta_symbols + input_symbols]\n",
    "        self.indices = tf.constant([sorted(symbols).index(a) for a in symbols])\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.empty_circuit = tfq.convert_to_tensor([cirq.Circuit()])\n",
    "        self.computation_layer = tfq.layers.ControlledPQC(circuit, observables)        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs[0] = encoding data for the state.\n",
    "        batch_dim = tf.gather(tf.shape(inputs[0]), 0)\n",
    "        tiled_up_circuits = tf.repeat(self.empty_circuit, repeats=batch_dim)\n",
    "        tiled_up_thetas = tf.tile(self.theta, multiples=[batch_dim, 1])\n",
    "        tiled_up_inputs = tf.tile(inputs[0], multiples=[1, self.n_layers])\n",
    "        scaled_inputs = tf.einsum(\"i,ji->ji\", self.lmbd, tiled_up_inputs)\n",
    "        squashed_inputs = tf.keras.layers.Activation(self.activation)(scaled_inputs)\n",
    "\n",
    "        joined_vars = tf.concat([tiled_up_thetas, squashed_inputs], axis=1)\n",
    "        joined_vars = tf.gather(joined_vars, self.indices, axis=1)\n",
    "        \n",
    "        return self.computation_layer([tiled_up_circuits, joined_vars])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deep Q-learning with PQC Q-function approximators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will move to the implementation of the deep Q-learning algorithm presented in <a href=\"https://arxiv.org/abs/2103.15084\" class=\"external\">[2]</a>. As opposed to a policy-gradient approach, the deep Q-learning method uses a PQC to approximate the Q-function of the agent. That is, the PQC defines a function approximator:\n",
    "$$ Q_\\theta(s,a) = \\langle O_a \\rangle_{s,\\theta} $$\n",
    "where $\\langle O_a \\rangle_{s,\\theta}$ are expectation values of observables $O_a$ (one per action) measured at the ouput of the PQC.\n",
    "\n",
    "These Q-values are updated using a loss function derived from Q-learning:\n",
    "$$ \\mathcal{L}(\\theta) = \\frac{1}{|\\mathcal{B}|}\\sum_{s,a,r,s' \\in \\mathcal{B}} \\left(Q_\\theta(s,a) - [r +\\max_{a'} Q_{\\theta'}(s',a')]\\right)^2$$\n",
    "for a batch $\\mathcal{B}$ of $1$-step interactions $(s,a,r,s')$ with the environment, sampled from the replay memory, and parameters $\\theta'$ specifying the target PQC (i.e., a copy of the main PQC, whose parameters are sporadically copied from the main PQC throughout learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can adopt the same observables used in <a href=\"https://arxiv.org/abs/2103.15084\" class=\"external\">[2]</a> for CartPole, namely a $Z_0Z_1$ Pauli product for action $0$ and a $Z_2Z_3$ Pauli product for action $1$. Both observables are re-scaled so their expectation values are in $[0,1]$ and weighted by an action-specific weight. To implement the re-scaling and weighting of the Pauli products, you can define again an extra `tf.keras.layers.Layer` that stores the action-specific weights and applies them multiplicatively on the expectation values $\\left(1+\\langle Z_0Z_1 \\rangle_{s,\\theta}\\right)/2$ and $\\left(1+\\langle Z_2Z_3 \\rangle_{s,\\theta}\\right)/2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Rescaling(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Rescaling, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=tf.ones(shape=(1,input_dim)), dtype=\"float32\",\n",
    "            trainable=True, name=\"obs-weights\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.math.multiply((inputs+1)/2, tf.repeat(self.w,repeats=tf.shape(inputs)[0],axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the definition of your PQC and its observables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_qubits = 4 # Dimension of the state vectors in CartPole\n",
    "n_layers = 5 # Number of layers in the PQC\n",
    "n_actions = 2 # Number of actions in CartPole\n",
    "\n",
    "qubits = cirq.GridQubit.rect(1, n_qubits)\n",
    "ops = [cirq.Z(q) for q in qubits]\n",
    "observables = [ops[0]*ops[1], ops[2]*ops[3]] # Z_0*Z_1 for action 0 and Z_2*Z_3 for action 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a `tf.keras.Model` that, similarly to the PQC-policy model, constructs a Q-function approximator that is used to generate the main and target models of our Q-learning agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_model_Qlearning(qubits, n_layers, n_actions, observables, target):\n",
    "    \"\"\"Generates a Keras model for a data re-uploading PQC Q-function approximator.\"\"\"\n",
    "\n",
    "    input_tensor = tf.keras.Input(shape=(len(qubits), ), dtype=tf.dtypes.float32, name='input')\n",
    "    re_uploading_pqc = ReUploadingPQC(qubits, n_layers, observables, activation='tanh')([input_tensor])\n",
    "    process = tf.keras.Sequential([Rescaling(len(observables))], name=target*\"Target\"+\"Q-values\")\n",
    "    Q_values = process(re_uploading_pqc)\n",
    "    model = tf.keras.Model(inputs=[input_tensor], outputs=Q_values)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = generate_model_Qlearning(qubits, n_layers, n_actions, observables, False)\n",
    "model_target = generate_model_Qlearning(qubits, n_layers, n_actions, observables, True)\n",
    "\n",
    "model_target.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "re-uploading_PQC (ReUploadin (None, 2)                 92        \n",
      "_________________________________________________________________\n",
      "Q-values (Sequential)        (None, 2)                 2         \n",
      "=================================================================\n",
      "Total params: 94\n",
      "Trainable params: 94\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model_target, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "re-uploading_PQC (ReUploadin (None, 2)                 92        \n",
      "_________________________________________________________________\n",
      "TargetQ-values (Sequential)  (None, 2)                 2         \n",
      "=================================================================\n",
      "Total params: 94\n",
      "Trainable params: 94\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_target.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now implement the deep Q-learning algorithm and test it on the CartPole-v1 environment. For the policy of the agent, you can use an $\\varepsilon$-greedy policy:\n",
    "$$ \\pi(a|s) =\n",
    "\\begin{cases}\n",
    "\\delta_{a,\\text{argmax}_{a'} Q_\\theta(s,a')}\\quad \\text{w.p.}\\quad 1 - \\varepsilon\\\\\n",
    "\\frac{1}{\\text{num_actions}}\\quad \\quad \\quad \\quad \\text{w.p.}\\quad \\varepsilon\n",
    "\\end{cases} $$\n",
    "where $\\varepsilon$ is multiplicatively decayed at each episode of interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by defining a function that performs an interaction step in the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def interact_env(state, model, epsilon, n_actions, env):\n",
    "    # Preprocess state\n",
    "    state_array = np.array(state) \n",
    "    state = tf.convert_to_tensor([state_array])\n",
    "\n",
    "    # Sample action\n",
    "    coin = np.random.random()\n",
    "    if coin > epsilon:\n",
    "        q_vals = model([state])\n",
    "        action = int(tf.argmax(q_vals[0]).numpy())\n",
    "    else:\n",
    "        action = np.random.choice(n_actions)\n",
    "\n",
    "    # Apply sampled action in the environment, receive reward and next state\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "    interaction = {'state': state_array, 'action': action, 'next_state': next_state.copy(),\n",
    "                   'reward': reward, 'done':float(done)}\n",
    "    \n",
    "    return interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a function that updates the Q-function using a batch of interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def Q_learning_update(states, actions, rewards, next_states, done, model, gamma, n_actions):\n",
    "    states = tf.convert_to_tensor(states)\n",
    "    actions = tf.convert_to_tensor(actions)\n",
    "    rewards = tf.convert_to_tensor(rewards)\n",
    "    next_states = tf.convert_to_tensor(next_states)\n",
    "    done = tf.convert_to_tensor(done)\n",
    "\n",
    "    # Compute their target q_values and the masks on sampled actions\n",
    "    future_rewards = model_target([next_states])\n",
    "    target_q_values = rewards + (gamma * tf.reduce_max(future_rewards, axis=1)\n",
    "                                                   * (1.0 - done))\n",
    "    masks = tf.one_hot(actions, n_actions)\n",
    "\n",
    "    # Train the model on the states and target Q-values\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(model.trainable_variables)\n",
    "        q_values = model([states])\n",
    "        q_values_masked = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "        loss = tf.keras.losses.Huber()(target_q_values, q_values_masked)\n",
    "\n",
    "    # Backpropagation\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    for optimizer, w in zip([optimizer_in, optimizer_var, optimizer_out], [w_in, w_var, w_out]):\n",
    "        optimizer.apply_gradients([(grads[w], model.trainable_variables[w])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "n_episodes = 2000\n",
    "\n",
    "# Define replay memory\n",
    "max_memory_length = 10000 # Maximum replay length\n",
    "replay_memory = deque(maxlen=max_memory_length)\n",
    "\n",
    "epsilon = 1.0  # Epsilon greedy parameter\n",
    "epsilon_min = 0.01  # Minimum epsilon greedy parameter\n",
    "decay_epsilon = 0.99 # Decay rate of epsilon greedy parameter\n",
    "batch_size = 16\n",
    "steps_per_update = 10 # Train the model every x steps\n",
    "steps_per_target_update = 30 # Update the target model every x steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the optimizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer_in = tf.keras.optimizers.Adam(learning_rate=0.001, amsgrad=True)\n",
    "optimizer_var = tf.keras.optimizers.Adam(learning_rate=0.001, amsgrad=True)\n",
    "optimizer_out = tf.keras.optimizers.Adam(learning_rate=0.1, amsgrad=True)\n",
    "\n",
    "# Assign the model parameters to each optimizer\n",
    "w_in, w_var, w_out = 1, 0, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the main training loop of the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This agent may need to simulate several million quantum circuits and can take as much as ~40 minutes to finish training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026e56d55bcc435b821b7456d55864ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-23 18:18:04.877487: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-09-23 18:18:04.899888: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3400005000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10/2000, average last 10 rewards 20.7\n",
      "Episode 20/2000, average last 10 rewards 21.2\n",
      "Episode 30/2000, average last 10 rewards 22.2\n",
      "Episode 40/2000, average last 10 rewards 13.8\n",
      "Episode 50/2000, average last 10 rewards 14.1\n",
      "Episode 60/2000, average last 10 rewards 14.6\n",
      "Episode 70/2000, average last 10 rewards 14.1\n",
      "Episode 80/2000, average last 10 rewards 15.7\n",
      "Episode 90/2000, average last 10 rewards 20.3\n",
      "Episode 100/2000, average last 10 rewards 22.1\n",
      "Episode 110/2000, average last 10 rewards 22.1\n",
      "Episode 120/2000, average last 10 rewards 20.4\n",
      "Episode 130/2000, average last 10 rewards 22.3\n",
      "Episode 140/2000, average last 10 rewards 25.4\n",
      "Episode 150/2000, average last 10 rewards 27.0\n",
      "Episode 160/2000, average last 10 rewards 24.0\n",
      "Episode 170/2000, average last 10 rewards 26.8\n",
      "Episode 180/2000, average last 10 rewards 21.3\n",
      "Episode 190/2000, average last 10 rewards 22.8\n",
      "Episode 200/2000, average last 10 rewards 23.0\n",
      "Episode 210/2000, average last 10 rewards 22.1\n",
      "Episode 220/2000, average last 10 rewards 23.0\n",
      "Episode 230/2000, average last 10 rewards 23.7\n",
      "Episode 240/2000, average last 10 rewards 25.3\n",
      "Episode 250/2000, average last 10 rewards 27.6\n",
      "Episode 260/2000, average last 10 rewards 23.3\n",
      "Episode 270/2000, average last 10 rewards 29.6\n",
      "Episode 280/2000, average last 10 rewards 22.8\n",
      "Episode 290/2000, average last 10 rewards 26.1\n",
      "Episode 300/2000, average last 10 rewards 23.9\n",
      "Episode 310/2000, average last 10 rewards 20.5\n",
      "Episode 320/2000, average last 10 rewards 22.3\n",
      "Episode 330/2000, average last 10 rewards 22.6\n",
      "Episode 340/2000, average last 10 rewards 24.2\n",
      "Episode 350/2000, average last 10 rewards 22.8\n",
      "Episode 360/2000, average last 10 rewards 24.4\n",
      "Episode 370/2000, average last 10 rewards 25.0\n",
      "Episode 380/2000, average last 10 rewards 24.4\n",
      "Episode 390/2000, average last 10 rewards 21.8\n",
      "Episode 400/2000, average last 10 rewards 24.1\n",
      "Episode 410/2000, average last 10 rewards 29.7\n",
      "Episode 420/2000, average last 10 rewards 30.6\n",
      "Episode 430/2000, average last 10 rewards 27.6\n",
      "Episode 440/2000, average last 10 rewards 26.4\n",
      "Episode 450/2000, average last 10 rewards 30.3\n",
      "Episode 460/2000, average last 10 rewards 21.6\n",
      "Episode 470/2000, average last 10 rewards 24.5\n",
      "Episode 480/2000, average last 10 rewards 30.5\n",
      "Episode 490/2000, average last 10 rewards 32.5\n",
      "Episode 500/2000, average last 10 rewards 36.8\n",
      "Episode 510/2000, average last 10 rewards 36.1\n",
      "Episode 520/2000, average last 10 rewards 59.7\n",
      "Episode 530/2000, average last 10 rewards 36.2\n",
      "Episode 540/2000, average last 10 rewards 28.8\n",
      "Episode 550/2000, average last 10 rewards 34.3\n",
      "Episode 560/2000, average last 10 rewards 36.3\n",
      "Episode 570/2000, average last 10 rewards 35.4\n",
      "Episode 580/2000, average last 10 rewards 43.4\n",
      "Episode 590/2000, average last 10 rewards 52.2\n",
      "Episode 600/2000, average last 10 rewards 60.5\n",
      "Episode 610/2000, average last 10 rewards 106.5\n",
      "Episode 620/2000, average last 10 rewards 94.2\n",
      "Episode 630/2000, average last 10 rewards 150.0\n",
      "Episode 640/2000, average last 10 rewards 188.2\n",
      "Episode 650/2000, average last 10 rewards 268.6\n",
      "Episode 660/2000, average last 10 rewards 374.2\n",
      "Episode 670/2000, average last 10 rewards 384.6\n",
      "Episode 680/2000, average last 10 rewards 425.8\n",
      "Episode 690/2000, average last 10 rewards 318.0\n",
      "Episode 700/2000, average last 10 rewards 281.6\n",
      "Episode 710/2000, average last 10 rewards 330.0\n",
      "Episode 720/2000, average last 10 rewards 246.3\n",
      "Episode 730/2000, average last 10 rewards 154.2\n",
      "Episode 740/2000, average last 10 rewards 111.3\n",
      "Episode 750/2000, average last 10 rewards 318.1\n",
      "Episode 760/2000, average last 10 rewards 423.6\n",
      "Episode 770/2000, average last 10 rewards 441.9\n",
      "Episode 780/2000, average last 10 rewards 384.4\n",
      "Episode 790/2000, average last 10 rewards 281.6\n",
      "Episode 800/2000, average last 10 rewards 293.2\n",
      "Episode 810/2000, average last 10 rewards 216.2\n",
      "Episode 820/2000, average last 10 rewards 233.8\n",
      "Episode 830/2000, average last 10 rewards 210.8\n",
      "Episode 840/2000, average last 10 rewards 250.7\n",
      "Episode 850/2000, average last 10 rewards 224.2\n",
      "Episode 860/2000, average last 10 rewards 204.6\n",
      "Episode 870/2000, average last 10 rewards 268.4\n",
      "Episode 880/2000, average last 10 rewards 260.8\n",
      "Episode 890/2000, average last 10 rewards 241.0\n",
      "Episode 900/2000, average last 10 rewards 334.9\n",
      "Episode 910/2000, average last 10 rewards 269.4\n",
      "Episode 920/2000, average last 10 rewards 344.0\n",
      "Episode 930/2000, average last 10 rewards 291.3\n",
      "Episode 940/2000, average last 10 rewards 299.3\n",
      "Episode 950/2000, average last 10 rewards 315.9\n",
      "Episode 960/2000, average last 10 rewards 403.4\n",
      "Episode 970/2000, average last 10 rewards 259.7\n",
      "Episode 980/2000, average last 10 rewards 363.4\n",
      "Episode 990/2000, average last 10 rewards 401.7\n",
      "Episode 1000/2000, average last 10 rewards 285.8\n",
      "Episode 1010/2000, average last 10 rewards 278.2\n",
      "Episode 1020/2000, average last 10 rewards 337.7\n",
      "Episode 1030/2000, average last 10 rewards 348.1\n",
      "Episode 1040/2000, average last 10 rewards 314.3\n",
      "Episode 1050/2000, average last 10 rewards 349.8\n",
      "Episode 1060/2000, average last 10 rewards 418.2\n",
      "Episode 1070/2000, average last 10 rewards 410.6\n",
      "Episode 1080/2000, average last 10 rewards 374.6\n",
      "Episode 1090/2000, average last 10 rewards 376.6\n",
      "Episode 1100/2000, average last 10 rewards 377.5\n",
      "Episode 1110/2000, average last 10 rewards 351.6\n",
      "Episode 1120/2000, average last 10 rewards 300.8\n",
      "Episode 1130/2000, average last 10 rewards 371.3\n",
      "Episode 1140/2000, average last 10 rewards 318.2\n",
      "Episode 1150/2000, average last 10 rewards 348.1\n",
      "Episode 1160/2000, average last 10 rewards 325.5\n",
      "Episode 1170/2000, average last 10 rewards 324.4\n",
      "Episode 1180/2000, average last 10 rewards 328.1\n",
      "Episode 1190/2000, average last 10 rewards 320.2\n",
      "Episode 1200/2000, average last 10 rewards 325.3\n",
      "Episode 1210/2000, average last 10 rewards 340.2\n",
      "Episode 1220/2000, average last 10 rewards 348.8\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_175818/3997992385.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0;31m# Interact with env\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m         \u001B[0minteraction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minteract_env\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepsilon\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_actions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m         \u001B[0;31m# Store interaction in the replay memory\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_175818/3125027993.py\u001B[0m in \u001B[0;36minteract_env\u001B[0;34m(state, model, epsilon, n_actions, env)\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcoin\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mepsilon\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0mq_vals\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m         \u001B[0maction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mq_vals\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0maction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchoice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_actions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/QML/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    204\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    205\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 206\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    207\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    208\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/QML/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001B[0m in \u001B[0;36m_slice_helper\u001B[0;34m(tensor, slice_spec, var)\u001B[0m\n\u001B[1;32m   1038\u001B[0m       \u001B[0mvar_empty\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconstant\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1039\u001B[0m       \u001B[0mpacked_begin\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpacked_end\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpacked_strides\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvar_empty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1040\u001B[0;31m     return strided_slice(\n\u001B[0m\u001B[1;32m   1041\u001B[0m         \u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1042\u001B[0m         \u001B[0mpacked_begin\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/QML/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    204\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    205\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 206\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    207\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    208\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/QML/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001B[0m in \u001B[0;36mstrided_slice\u001B[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001B[0m\n\u001B[1;32m   1211\u001B[0m     \u001B[0mstrides\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mones_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbegin\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1212\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1213\u001B[0;31m   op = gen_array_ops.strided_slice(\n\u001B[0m\u001B[1;32m   1214\u001B[0m       \u001B[0minput\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minput_\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1215\u001B[0m       \u001B[0mbegin\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbegin\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/QML/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001B[0m in \u001B[0;36mstrided_slice\u001B[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001B[0m\n\u001B[1;32m  10497\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mtld\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_eager\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  10498\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m> 10499\u001B[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001B[0m\u001B[1;32m  10500\u001B[0m         \u001B[0m_ctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"StridedSlice\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbegin\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstrides\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"begin_mask\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  10501\u001B[0m         \u001B[0mbegin_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"end_mask\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mend_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ellipsis_mask\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mellipsis_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "    \n",
    "episode_reward_history = []\n",
    "step_count = 0\n",
    "t = trange(n_episodes, desc='Training', leave=True)\n",
    "\n",
    "\n",
    "for episode in t:\n",
    "    episode_reward = 0\n",
    "    state = env.reset()\n",
    "    while True:\n",
    "        # Interact with env\n",
    "        interaction = interact_env(state, model, epsilon, n_actions, env)\n",
    "        \n",
    "        # Store interaction in the replay memory\n",
    "        replay_memory.append(interaction)\n",
    "        \n",
    "        state = interaction['next_state']\n",
    "        episode_reward += interaction['reward']\n",
    "        step_count += 1\n",
    "        \n",
    "        # Update model\n",
    "        if step_count % steps_per_update == 0:\n",
    "            # Sample a batch of interactions and update Q_function\n",
    "            training_batch = np.random.choice(replay_memory, size=batch_size)\n",
    "            Q_learning_update(np.asarray([x['state'] for x in training_batch]),\n",
    "                              np.asarray([x['action'] for x in training_batch]),\n",
    "                              np.asarray([x['reward'] for x in training_batch], dtype=np.float32),\n",
    "                              np.asarray([x['next_state'] for x in training_batch]),\n",
    "                              np.asarray([x['done'] for x in training_batch], dtype=np.float32),\n",
    "                              model, gamma, n_actions)\n",
    "        \n",
    "        # Update target model\n",
    "        if step_count % steps_per_target_update == 0:\n",
    "            model_target.set_weights(model.get_weights())\n",
    "        \n",
    "        # Check if the episode is finished\n",
    "        if interaction['done']:\n",
    "            break\n",
    "\n",
    "    # Decay epsilon\n",
    "    epsilon = max(epsilon * decay_epsilon, epsilon_min)\n",
    "    episode_reward_history.append(episode_reward)\n",
    "    wandb.log({'episode_reward': episode_reward}, step=step_count)\n",
    "\n",
    "    if (episode+1)%10 == 0:\n",
    "        avg_rewards = np.mean(episode_reward_history[-10:])\n",
    "        print(\"Episode {}/{}, average last 10 rewards {}\".format(\n",
    "            episode+1, n_episodes, avg_rewards))\n",
    "        wandb.log({'episode_reward_avg_last_10': avg_rewards, 'episode':episode+1}, step=step_count)\n",
    "        t.set_description(\"Episode {}/{}, average last 10 rewards {}\".format(episode+1, n_episodes, avg_rewards))\n",
    "        t.refresh() # to show immediately the update\n",
    "        if avg_rewards >= 500.0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the learning history of the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(episode_reward_history)\n",
    "plt.xlabel('Epsiode')\n",
    "plt.ylabel('Collected rewards')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the plot above, you should see that after ~1000 episodes, the performance of the agent gets close to optimal, i.e., 500 rewards per episode. Learning takes longer for Q-learning agents since the Q-function is a \"richer\" function to be learned than the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process wandb_internal:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 152, in wandb_internal\n",
      "    thread.join()\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/multiprocessing/spawn.py\", line 129, in _main\n",
      "    return self._bootstrap(parent_sentinel)\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/multiprocessing/process.py\", line 333, in _bootstrap\n",
      "    threading._shutdown()\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/threading.py\", line 1388, in _shutdown\n",
      "    lock.acquire()\n",
      "KeyboardInterrupt\n",
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 185, in check_network_status\n",
      "    status_response = self._interface.communicate_network_status()\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 749, in communicate_network_status\n",
      "    resp = self._communicate(req, timeout=timeout, local=True)\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 539, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 544, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n",
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 203, in check_status\n",
      "    status_response = self._interface.communicate_stop_status()\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 737, in communicate_stop_status\n",
      "    resp = self._communicate(req, timeout=timeout, local=True)\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 539, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 544, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n",
      "Error in atexit._run_exitfuncs:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 1583, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 1719, in _on_finish\n",
      "    self.history._flush()\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/wandb_history.py\", line 59, in _flush\n",
      "    self._callback(row=self._data, step=self._step)\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 906, in _history_callback\n",
      "    self._backend.interface.publish_history(\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 224, in publish_history\n",
      "    self._publish_history(history)\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 203, in _publish_history\n",
      "    self._publish(rec)\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 530, in _publish\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 1592, in _atexit_cleanup\n",
      "    self._backend.cleanup()\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/backend/backend.py\", line 167, in cleanup\n",
      "    self.interface.join()\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 830, in join\n",
      "    _ = self._communicate(record)\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 539, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/home/lh/miniconda3/envs/QML/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 544, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "state = env.reset()\n",
    "frames = []\n",
    "for t in range(500):\n",
    "    im = Image.fromarray(env.render(mode='rgb_array'))\n",
    "    frames.append(im)\n",
    "    q_vals = model([state])\n",
    "    action = int(tf.argmax(q_vals[0]).numpy())\n",
    "    state, _, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break\n",
    "env.close()\n",
    "frames[1].save('./images/gym_CartPole.gif',  save_all=True, append_images=frames[2:], optimize=False, duration=40, loop=0)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "jxWGru_NwpUK",
    "_u3QBKbvwpUP",
    "X8X49f8owpUe"
   ],
   "name": "quantum_reinforcement_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}